Iâ€™ll give you:

1. âœ… `link` and `link_error` (success & failure callbacks)
2. âœ… `chain` pipeline example (data â†’ preprocess â†’ train â†’ evaluate)
   with **full worker + client code** style.

Assume:

* Redis backend enabled
* RabbitMQ/Redis broker working

---

# âœ… 1. `link` and `link_error` â€” success & failure callbacks

## ğŸ¯ Use case

After task finishes:

* on success â†’ log / store result
* on failure â†’ alert / cleanup / retry pipeline

---

## Worker: `app/worker.py`

```python
import os, time, random
from celery import Celery
from dotenv import load_dotenv

load_dotenv()

app = Celery(
    "demo",
    broker=os.getenv("CELERY_BROKER_URL"),
    backend=os.getenv("CELERY_BACKEND_URL"),
)

# -----------------------
# Main task
# -----------------------
@app.task
def risky_division(x, y):
    time.sleep(2)
    return x / y   # may crash if y == 0

# -----------------------
# Success callback
# -----------------------
@app.task
def on_success(result):
    print("âœ… SUCCESS CALLBACK: result =", result)

# -----------------------
# Failure callback
# -----------------------
@app.task
def on_fail(request, exc, traceback):
    print("âŒ FAILURE CALLBACK:", exc)
```

âš ï¸ Failure callback receives `(request, exc, traceback)` â€” different signature!

---

## Client: `app/client.py`

```python
from app.worker import risky_division, on_success, on_fail

sig = risky_division.s(10, 0)  # will fail

sig.link(on_success.s())
sig.link_error(on_fail.s())

sig.apply_async()
print("Task submitted")
```

---

## What happens

If success:

```
risky_division â†’ on_success(result)
```

If failure:

```
risky_division â†’ on_fail(request, exception, traceback)
```

Callbacks run as **separate Celery tasks**, not in client.

---

# âœ… 2. `chain` â€” ML-style pipeline

## ğŸ¯ Use case

Classic ML pipeline:

```
load â†’ preprocess â†’ train â†’ evaluate
```

Each step runs on worker, possibly different machines.

---

## Worker: `app/worker.py`

```python
@app.task
def load_data():
    print("Loading data...")
    return [1, 2, 3, 4, 5]

@app.task
def preprocess(data):
    print("Preprocessing...")
    return [x * 2 for x in data]

@app.task
def train_model(data):
    print("Training model...")
    model = {"mean": sum(data) / len(data)}
    return model

@app.task
def evaluate(model):
    print("Evaluating...")
    return {"accuracy": model["mean"] / 10}
```

---

## Client: `app/client.py`

```python
from celery import chain
from app.worker import load_data, preprocess, train_model, evaluate

job = chain(
    load_data.s(),
    preprocess.s(),
    train_model.s(),
    evaluate.s(),
)()

print("Final result:", job.get(timeout=60))
```

---

## What happens internally

1. Worker runs `load_data()`
2. Its result is sent to `preprocess(data)`
3. Then into `train_model(data)`
4. Then into `evaluate(model)`
5. Final output returned to client

Each step may run on **different workers**.

---

# ğŸ”¥ Advanced: combine chain + group + chord

Example: preprocess in parallel, then train.

```
load
 â†“
group(preprocess chunks)
 â†“
reduce
 â†“
train
```

Thatâ€™s how you build **distributed ML pipelines** in Celery.

---

# âš ï¸ Important design notes

### âœ” Callbacks are async tasks

They do NOT block original task.

### âœ” Chains propagate failure

If `train_model` fails:

* `evaluate` will NOT run

### âœ” link_error is per-task

Chains have their own error handling too.

---

# When to use what

| Pattern      | Use                      |
| ------------ | ------------------------ |
| `link`       | fire callback after task |
| `link_error` | notify on failure        |
| `chain`      | linear pipeline          |
| `group`      | parallel batch           |
| `chord`      | map-reduce               |

These form Celeryâ€™s **distributed DAG engine**.

